{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$. Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "\n",
    "подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "\n",
    "возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "\n",
    "расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('WarAndPeace.txt') as f:\n",
    "    war_and_peace = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ' абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "random.seed(123)\n",
    "\n",
    "def remove_punct(text,alphabet):\n",
    "    return ''.join(char for char in text.lower() if char in alphabet)\n",
    "\n",
    "def frequencies(text):\n",
    "    counts = Counter(text)\n",
    "    for letter in counts.keys():\n",
    "        counts[letter] = counts[letter]/len(text)\n",
    "    freqs = dict(sorted(counts.items(), key = lambda x:x[1], reverse = True))\n",
    "    return freqs\n",
    "\n",
    "def encode(text,freqs):\n",
    "    res = []\n",
    "    relation = dict(zip(freqs, np.random.permutation(list(freqs))))\n",
    "    for char in text:\n",
    "        res.append(relation[char])\n",
    "    return ''.join(r for r in res)\n",
    "\n",
    "def decode(text,text_freqs,freqs):\n",
    "    res = []\n",
    "    relation = dict(zip(text_freqs, freqs))\n",
    "    for char in text:\n",
    "        res.append(relation[char])    \n",
    "    return ''.join(r for r in res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0.17037373325433405, 'о': 0.09430974384228873, 'а': 0.069574250340492, 'е': 0.06543448318315777, 'и': 0.055152778953362215, 'н': 0.054046276133242026, 'т': 0.04712101508937434, 'с': 0.04328749836486892, 'л': 0.04197785455412861, 'в': 0.03820281781177141, 'р': 0.03781192529951754, 'к': 0.02974476565686101, 'д': 0.02521872282796882, 'м': 0.024530813564277963, 'у': 0.023782885371540254, 'п': 0.021309797705430174, 'я': 0.019201440454297124, 'г': 0.017200809486068683, 'ь': 0.016155864541893983, 'ы': 0.01574804361375511, 'з': 0.014776968120714995, 'б': 0.014327595626312913, 'ч': 0.011309720758085243, 'й': 0.009556860240537401, 'ж': 0.008402650066559453, 'ш': 0.007833239714063666, 'х': 0.007079155733731407, 'ю': 0.005378619410737233, 'ц': 0.003353365292130595, 'э': 0.0025069444978801005, 'щ': 0.0023299656045368154, 'ф': 0.0018605868004524504, 'ё': 0.0006632861133126602, 'ъ': 0.00043552197231434527}\n"
     ]
    }
   ],
   "source": [
    "war_and_peace = remove_punct(war_and_peace,alphabet)\n",
    "freqs = frequencies(war_and_peace)\n",
    "print(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ответа не было кроме того общего ответа который дает жизнь на все самые сложные и неразрешимые вопросы ответ этот надо жить потребностями дня то есть забыться забыться сном уже нельзя по крайней мере до ночи нельзя уже вернуться к той музыке которую пели графинчики  женщины стало быть надо забыться сном жизни\n"
     ]
    }
   ],
   "source": [
    "sentence = '''Ответа не было, кроме того общего ответа, который дает жизнь на все самые сложные и \n",
    "неразрешимые вопросы. Ответ этот: надо жить потребностями дня, то есть забыться. Забыться сном уже нельзя, \n",
    "по крайней мере до ночи, нельзя уже вернуться к той музыке, которую пели графинчики - женщины; стало быть, \n",
    "надо забыться сном жизни.'''\n",
    "\n",
    "sentence_filtered = remove_punct(sentence, alphabet)\n",
    "print(sentence_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Закодированное предложение:\n",
      "енхйнямжймэиаемдкерймнещемеэыйщеменхйнямденекиюмшяйнмогёжумжямхлймляриймлаеожиймгмжйкяёкйчгриймхеткелименхйнмбненмжяшемогнумтенкйэжелнзргмшжзмнемйлнумёяэинулзмёяэинулзмлжерм оймжйауёзмтемдкяюжйюмрйкймшемжецгмжйауёзм оймхйкж нулзмдмнеюмр ёидймденек пмтйагмщкяъгжцгдгммойжыгжимлняаемэинумжяшемёяэинулзмлжермогёжг\n"
     ]
    }
   ],
   "source": [
    "sentence_encoded = encode(sentence_filtered,freqs)\n",
    "print('Закодированное предложение:')\n",
    "print(sentence_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Раскодированное предложение:\n",
      "оегаен иа ульо пвода еойо оужайо оегаен поеовлб ынае яткир ин гса сндла сьояила т иавнквахтдла гочвосл оегае юеое иныо ятер чоевауиосемдт ыим ео асер кнулерсм кнулерсм сиод зяа иаьркм чо пвнбиаб дава ыо иошт иаьркм зяа гавизерсм п еоб дзклпа поеовзц чаьт йвнэтиштпт  яаижтил сеньо улер иныо кнулерсм сиод яткит\n"
     ]
    }
   ],
   "source": [
    "sentence_freqs = frequencies(sentence_encoded)\n",
    "sentence_decoded = decode(sentence_encoded,sentence_freqs, freqs)\n",
    "print('Раскодированное предложение:')\n",
    "print(sentence_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(sent_1, sent_2):\n",
    "    assert len(sent_1) == len(sent_2)\n",
    "    correct = 0\n",
    "    for char_1, char_2 in zip(sent_1, sent_2):\n",
    "        correct += (char_1 == char_2)\n",
    "    return correct / len(sent_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.300000\n"
     ]
    }
   ],
   "source": [
    "print('%2f' % accuracy(sentence_filtered, sentence_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$. Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. \n",
    "Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "\n",
    "* подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "\n",
    "* проведите тестирование аналогично п.1, но при помощи биграмм.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_frequencies(text):\n",
    "    counts = Counter([text[i:i + 2] for i in range(len(text) - 1)])\n",
    "    for letter in counts.keys():\n",
    "        counts[letter] = counts[letter]/len(text)\n",
    "    freqs = dict(sorted(counts.items(), key = lambda x:x[1], reverse = True))\n",
    "    return freqs\n",
    "\n",
    "def decode_bigram(text,text_freqs,freqs):\n",
    "    res = []\n",
    "    relation = dict(zip(text_freqs, freqs))\n",
    "    for i in range(0, len(text)- 1, 2):\n",
    "        res.append(relation[text[i:i + 2]])    \n",
    "    return ''.join(r for r in res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_freqs = bigram_frequencies(war_and_peace)\n",
    "sentence_bigram_freqs = bigram_frequencies(sentence_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "е  кноа о   котоелрел  ри ы  зпрй по ирава вазка у истзаема ражео ойрио бымоано я  ненльестиер дняелсьй по иви вм роонстиннатьх руь нисяя вс п в анинала   снеослигоал пк овату а лоте птьтоентрисодоло она аяя  ногт ату  долди снетол амодвыиво ва вки эпеедиеенкнхобоя стшеадан онокооргонароонослигоал пк овстзатв\n"
     ]
    }
   ],
   "source": [
    "sentence_bigram_decoded = decode_bigram(sentence_encoded,sentence_bigram_freqs, bigram_freqs)\n",
    "print(sentence_bigram_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08709677419354839"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(sentence_filtered, sentence_bigram_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$. Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "\n",
    "* предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "\n",
    "* реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся алгоритмом Метрополиса-Гастингса. Каждую итерацию будем выбирать две случайных буквы из алфавита и  менять их вхождения местами. Далее оценим вероятность встретить такой текст. Посчитаем правдоподобие для этого текста как произведение вероятностей всех биграмм в нем. (Т.к. считаем логарифм правдоподобия, то будет сумма). Если значение правдоподобия изменненого текста больше правдоподобия исходного, то принимаем такую расшифровку, иначе принимаем ее с вероятностью $likelihood_{new}/likelihood_{cur}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMC_decoder:\n",
    "    \n",
    "    def __init__(self,alphabet, freqs, iterations=50000, print_every=10000):\n",
    "        self.alphabet = alphabet\n",
    "        self.iterations = iterations\n",
    "        self.print_every = print_every\n",
    "        self.freqs = freqs\n",
    "        \n",
    "        \n",
    "    def loglikelihood(self, text):\n",
    "        counts = Counter([''.join(text[i: i + 2]) for i in range(len(text) - 1)])\n",
    "        res = 0\n",
    "        for bigram, count in counts.items():\n",
    "            prob = self.freqs.get(bigram)\n",
    "            if prob is None:\n",
    "                prob = 1 / len(alphabet) ** 2        \n",
    "            res += count * np.log(prob)\n",
    "        return res\n",
    "        \n",
    "               \n",
    "    def accept(self,cur_likelihood, new_likelihood):\n",
    "        if new_likelihood > cur_likelihood:\n",
    "            return True\n",
    "        return np.random.rand() < np.exp(new_likelihood - cur_likelihood)\n",
    "    \n",
    "    \n",
    "    def change_text(self, text):\n",
    "        char_1, char_2 = np.random.choice(self.alphabet, 2, replace=False)\n",
    "        for i in range(len(text)):\n",
    "            if text[i] == char_1:\n",
    "                text[i] = char_2\n",
    "            elif text[i] == char_2:\n",
    "                text[i] = char_1\n",
    "        return text\n",
    "    \n",
    "        \n",
    "    def decode(self, text):\n",
    "        text_decoded = copy(text)\n",
    "        best_likelihood = cur_likelihood = self.loglikelihood(text)         \n",
    "        for i in range(self.iterations):\n",
    "            text_changed = self.change_text(copy(text))\n",
    "            likelihood_changed = self.loglikelihood(text_changed)\n",
    "            if self.accept(cur_likelihood, likelihood_changed):\n",
    "                text = text_changed\n",
    "                cur_likelihood = likelihood_changed\n",
    "                if cur_likelihood > best_likelihood:\n",
    "                    best_likelihood = cur_likelihood\n",
    "                    text_decoded = copy(text)        \n",
    "            if (i+1) % self.print_every == 0:\n",
    "                print('Iteration: ',i + 1)\n",
    "                print(f'Likelihood: {best_likelihood}')\n",
    "                print(''.join(text_decoded))\n",
    "                print()\n",
    "        return ''.join(text_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  10000\n",
      "Likelihood: -1739.769754255785\n",
      "алголе но быта крамо лаза абёоза алголе каларый чеол виднь не гсо семыо ставныо и норедрожимыо гапрасы алгол элал неча виль палробнаслями чня ла осль дебылься дебылься снам уво нотьдя па крейной моро ча наъи нотьдя уво горнулься к лай мудыко каларую поти зрешинъики  вонёины слета быль неча дебылься снам видни\n",
      "\n",
      "Iteration:  20000\n",
      "Likelihood: -1699.4460795125894\n",
      "отчета не было вроме того обёего отчета воторый зает дикнь на чсе самые слодные и неракрежимые чопросы отчет этот назо дить потребностями зня то есть кабыться кабыться сном уде нелькя по врайней мере зо ноъи нелькя уде чернуться в той мукыве воторую пели грашинъиви  денёины стало быть назо кабыться сном дикни\n",
      "\n",
      "Iteration:  30000\n",
      "Likelihood: -1698.1637934042253\n",
      "ответа не было дроме того обёего ответа доторый зает чикнь на все самые слочные и неракрежимые вопросы ответ этот назо чить потребностями зня то есть кабыться кабыться сном уче нелькя по драйней мере зо ноъи нелькя уче вернуться д той мукыде доторую пели грашинъиди  ченёины стало быть назо кабыться сном чикни\n",
      "\n",
      "Iteration:  40000\n",
      "Likelihood: -1698.1637934042253\n",
      "ответа не было дроме того обёего ответа доторый зает чикнь на все самые слочные и неракрежимые вопросы ответ этот назо чить потребностями зня то есть кабыться кабыться сном уче нелькя по драйней мере зо ноъи нелькя уче вернуться д той мукыде доторую пели грашинъиди  ченёины стало быть назо кабыться сном чикни\n",
      "\n",
      "Iteration:  50000\n",
      "Likelihood: -1698.1637934042253\n",
      "ответа не было дроме того обёего ответа доторый зает чикнь на все самые слочные и неракрежимые вопросы ответ этот назо чить потребностями зня то есть кабыться кабыться сном уче нелькя по драйней мере зо ноъи нелькя уче вернуться д той мукыде доторую пели грашинъиди  ченёины стало быть назо кабыться сном чикни\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mcmc_decoder = MCMC_decoder(list(alphabet),bigram_freqs)\n",
    "\n",
    "sentence_mcmc_decoded = mcmc_decoder.decode(list(sentence_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8903225806451613"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(sentence_filtered, sentence_mcmc_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$4$.Расшифруйте сообщение:\n",
    "\n",
    "\n",
    "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←\n",
    "↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "message='''←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠← ↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  10000\n",
      "Likelihood: -1317.0622699880134\n",
      "еиса ву ваъане ромжыструь аса подна ромжыструь нелин х зного иоочюерая лономуь сегло пмоданынт иломее виего ву вией иъесыса пмывастро а посхдане жылиажыструь чысс бы поисеърее денвемное быъырае лхмиы коня лоредро я радего ре очеюыэ\n",
      "\n",
      "Iteration:  20000\n",
      "Likelihood: -1291.285858772247\n",
      "есни вы вилите ромжанурый ини подти ромжанурый текст я этого соочщерих котомый негко пмодитату скомее всего вы всеь сленани пмавинуро и понядите жаксижанурый чанн за поснелрее детвемтое заларие кямса ботх коредро х ридего ре очещаш\n",
      "\n",
      "Iteration:  30000\n",
      "Likelihood: -1287.8134745494406\n",
      "есни вы виките ромжанурый ини подти ромжанурый телст х этого соочёерия лотомый негло пмодитату сломее всего вы всеь скенани пмавинуро и понхдите жалсижанурый чанн за поснекрее детвемтое закарие лхмса ботя лоредро я ридего ре очеёаш\n",
      "\n",
      "Iteration:  40000\n",
      "Likelihood: -1278.6018729377113\n",
      "есни вы виёите дорканудый ини почти дорканудый телст х этого соомжедия лоторый негло прочитату слорее всего вы всеь сёенани правинудо и понхчите калсиканудый манн за поснеёдее четвертое заёадие лхрса ботя лодечдо я дичего де омежаш\n",
      "\n",
      "Iteration:  50000\n",
      "Likelihood: -1262.8439122419315\n",
      "если вы вимите нордальный или почти нордальный текст у этого соошжения который легко прочитать скорее всего вы всех смелали правильно и получите даксидальный шалл за послемнее четвертое замание курса ботя конечно я ничего не ошежаъ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_freqs = frequencies(message)\n",
    "message_decoded = decode(message,message_freqs,freqs)\n",
    "message_decoded_result = mcmc_decoder.decode(list(message_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бонус: какие вы можете придумать применения для этой модели? Пляшущие человечки ведь не так часто встречаются в жизни (хотя встречаются! и это самое потрясающее во всей этой истории, но об этом я расскажу потом).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, подобный метод можно применить расшифровки зашифрованных сообщений и файлов в неизвестной кодировке."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
